{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results bighifigan:-26.898960584617523\n",
      "\n",
      "Results bigvgan:-24.156062689172217\n",
      "\n",
      "Results bigvgan-base:-28.501391025910895\n",
      "\n",
      "Results hifigan:-28.573745922869946\n",
      "\n",
      "Results hifigan_mrd:-28.35362121793959\n",
      "\n",
      "Results mrd_snake:-17.38124105665419\n",
      "\n",
      "Results sc-wavernn:-37.40817304404385\n",
      "\n",
      "Results univnet:-28.953988155686712\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from pesq import pesq\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_pesq(ref, deg, fs):\n",
    "    \"\"\"\n",
    "    Compute the PESQ score.\n",
    "\n",
    "    Args:\n",
    "    ref : numpy.ndarray\n",
    "        Reference audio signal.\n",
    "    deg : numpy.ndarray\n",
    "        Degraded audio signal.\n",
    "    fs : int\n",
    "        Sampling frequency of the audio signals.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The PESQ score.\n",
    "    \"\"\"\n",
    "    ref = ref[0].numpy()\n",
    "    deg = deg[0].numpy()\n",
    "    # Ensure audio is not silent and has sufficient length\n",
    "    if len(ref) < fs * 0.3:  # Ensure at least 300 ms long\n",
    "        return float('nan')  # Return NaN if too short for PESQ\n",
    "    if np.all(ref == 0) or np.all(deg == 0):\n",
    "        return float('nan')  # Return NaN if silent\n",
    "\n",
    "    # Calculate PESQ\n",
    "    try:\n",
    "        return pesq(fs, ref, deg, 'wb')  # 'wb' is for wideband, use 'nb' for narrowband\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing PESQ: {e}\")\n",
    "        return float('nan')  # Return NaN on error\n",
    "\n",
    "def compute_ssnr(ref, deg, frame_size=256, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the Segmental Signal-to-Noise Ratio (SSNR).\n",
    "\n",
    "    Args:\n",
    "    ref : numpy.ndarray\n",
    "        Reference audio signal.\n",
    "    deg : numpy.ndarray\n",
    "        Degraded audio signal.\n",
    "    frame_size : int\n",
    "        The size of each frame for SSNR computation.\n",
    "    eps : float\n",
    "        Small number to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The mean SSNR over all frames.\n",
    "    \"\"\"\n",
    "    ref = ref[0].numpy()\n",
    "    deg = deg[0].numpy()\n",
    "    ssnr_values = []\n",
    "    for start in range(0, len(ref) - frame_size, frame_size):\n",
    "        ref_frame = ref[start:start + frame_size]\n",
    "        # if np.all(ref_frame == 0):\n",
    "        #     continue  # Skip completely silent frames\n",
    "        deg_frame = deg[start:start + frame_size]\n",
    "        noise = ref_frame - deg_frame\n",
    "        signal_energy = np.sum(ref_frame ** 2) + eps\n",
    "        noise_energy = np.sum(noise ** 2) + eps\n",
    "        ssnr_values.append(10 * np.log10(signal_energy / noise_energy))\n",
    "    \n",
    "    # Filter out non-finite values which might occur if the noise is zero\n",
    "    ssnr_values = [x for x in ssnr_values if np.isfinite(x)]\n",
    "    \n",
    "    return np.mean(ssnr_values) if ssnr_values else 0 #float('nan') \n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assert_is_audio(*signal: torch.Tensor):\n",
    "    for s in signal:\n",
    "        assert len(s.shape) == 2\n",
    "        assert s.shape[0] == 1 or s.shape[0] == 2\n",
    "\n",
    "\n",
    "def is_silent(signal: torch.Tensor, silence_threshold: float = 1.5e-5) -> bool:\n",
    "    assert_is_audio(signal)\n",
    "    num_samples = signal.shape[-1]\n",
    "    return torch.linalg.norm(signal) / num_samples < silence_threshold\n",
    "\n",
    "\n",
    "def sdr(preds: torch.Tensor, target: torch.Tensor, eps: float = 1e-5) -> torch.Tensor:\n",
    "    s_target = torch.norm(target, dim=-1)**2 + eps\n",
    "    s_error = torch.norm(target - preds, dim=-1)**2 + eps\n",
    "    return 10 * torch.log10(s_target/s_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sisnr(preds: torch.Tensor, target: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    alpha = (torch.sum(preds * target, dim=-1, keepdim=True) + eps) / (torch.sum(target**2, dim=-1, keepdim=True) + eps)\n",
    "    target_scaled = alpha * target\n",
    "    noise = target_scaled - preds\n",
    "    s_target = torch.sum(target_scaled**2, dim=-1) + eps\n",
    "    s_error = torch.sum(noise**2, dim=-1) + eps\n",
    "    return 10 * torch.log10(s_target / s_error)\n",
    "\n",
    "\n",
    "def evaluate_separations(\n",
    "    separation_path: Union[str, Path],\n",
    "    dataset_path: Union[str, Path],\n",
    "    separation_sr: int,\n",
    "    filter_single_source: bool = True,\n",
    "    eps: float = 1e-8,\n",
    "    chunk_duration: float = 4.0, \n",
    "    overlap_duration: float = 2.0,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    separation_path = Path(separation_path)\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    df_entries = defaultdict(list)\n",
    "\n",
    "    files = os.listdir(dataset_path)\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "\n",
    "        try:\n",
    "            # load seperated tracks and resample track\n",
    "            separated_track, _ = torchaudio.load(separation_path / file) # load_chunks(separation_path/str(forder_id), [\"mixture\"])\n",
    "\n",
    "            # load original track\n",
    "            original_track, _ = torchaudio.load(dataset_path / file) #load_chunks(dataset_path/str(forder_id), [\"mixture\"])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        chunk_samples = int(chunk_duration * separation_sr)\n",
    "        overlap_samples = int(overlap_duration * separation_sr)\n",
    "\n",
    "        # Calculate the step size between consecutive sub-chunks\n",
    "        step_size = chunk_samples - overlap_samples\n",
    "\n",
    "        # Determine the number of evaluation chunks based on step_size\n",
    "        num_eval_chunks = math.ceil((original_track.shape[-1] - overlap_samples) / step_size)-1\n",
    "            \n",
    "        for i in range(num_eval_chunks):\n",
    "            start_sample = i * step_size\n",
    "            end_sample = start_sample + chunk_samples\n",
    "            \n",
    "            # Determine number of active signals in sub-chunk\n",
    "            num_active_signals = 0\n",
    "            for k in separated_track:\n",
    "                o = original_track[:,start_sample:end_sample]\n",
    "                if not is_silent(o):\n",
    "                    num_active_signals += 1\n",
    "            \n",
    "            # Skip sub-chunk if necessary\n",
    "            if filter_single_source and num_active_signals < 1:\n",
    "                continue\n",
    "\n",
    "            # Compute SI-SNRi for each stem\n",
    "            o = original_track[:,start_sample:end_sample]\n",
    "            s = separated_track[:,start_sample:end_sample]\n",
    "\n",
    "            # df_entries[k].append((sisnr(s, o, eps) ) - sisnr(m, o, eps))\n",
    "\n",
    "            # df_entries[k].append((sdr(s, o, eps) ).item()) \n",
    "            df_entries[\"snr\"].append((sisnr(s, o, eps) ).item()) #- sisnr(m, o, eps))\n",
    "\n",
    "            # Compute PESQ\n",
    "            pesq_score = 0.0 #compute_pesq(o, s, separation_sr)\n",
    "            df_entries[\"pesq\"].append(pesq_score)\n",
    "\n",
    "            # Compute SSNR\n",
    "            ssnr_score = 0.0 #compute_ssnr(o, s)\n",
    "            df_entries[\"ssnr\"].append(ssnr_score)\n",
    "\n",
    "\n",
    "            # Add chunk and sub-chunk info to dataframe entry\n",
    "            df_entries[\"start_sample\"].append(start_sample)\n",
    "            df_entries[\"end_sample\"].append(end_sample)\n",
    "            df_entries[\"file\"].append(file)\n",
    "\n",
    "\n",
    "\n",
    "    # Create and return dataframe\n",
    "    return pd.DataFrame(df_entries)\n",
    "\n",
    "base_dir = \"/home/karchkhadze/testing_sisdr/samples/\"\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bighifigan\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bighifigan:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bigvgan\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bigvgan:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bigvgan-base\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bigvgan-base:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"hifigan\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults hifigan:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"hifigan_mrd\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults hifigan_mrd:{results[\"snr\"].mean()}')\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"mrd_snake\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults mrd_snake:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"sc-wavernn\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults sc-wavernn:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"univnet\"\n",
    "dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults univnet:{results[\"snr\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results bighifigan:-23.93779212550113\n",
      "\n",
      "Results bigvgan:-23.895018778349225\n",
      "\n",
      "Results bigvgan-base:-24.32210568377846\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from pesq import pesq\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_pesq(ref, deg, fs):\n",
    "    \"\"\"\n",
    "    Compute the PESQ score.\n",
    "\n",
    "    Args:\n",
    "    ref : numpy.ndarray\n",
    "        Reference audio signal.\n",
    "    deg : numpy.ndarray\n",
    "        Degraded audio signal.\n",
    "    fs : int\n",
    "        Sampling frequency of the audio signals.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The PESQ score.\n",
    "    \"\"\"\n",
    "    ref = ref[0].numpy()\n",
    "    deg = deg[0].numpy()\n",
    "    # Ensure audio is not silent and has sufficient length\n",
    "    if len(ref) < fs * 0.3:  # Ensure at least 300 ms long\n",
    "        return float('nan')  # Return NaN if too short for PESQ\n",
    "    if np.all(ref == 0) or np.all(deg == 0):\n",
    "        return float('nan')  # Return NaN if silent\n",
    "\n",
    "    # Calculate PESQ\n",
    "    try:\n",
    "        return pesq(fs, ref, deg, 'wb')  # 'wb' is for wideband, use 'nb' for narrowband\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing PESQ: {e}\")\n",
    "        return float('nan')  # Return NaN on error\n",
    "\n",
    "def compute_ssnr(ref, deg, frame_size=256, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the Segmental Signal-to-Noise Ratio (SSNR).\n",
    "\n",
    "    Args:\n",
    "    ref : numpy.ndarray\n",
    "        Reference audio signal.\n",
    "    deg : numpy.ndarray\n",
    "        Degraded audio signal.\n",
    "    frame_size : int\n",
    "        The size of each frame for SSNR computation.\n",
    "    eps : float\n",
    "        Small number to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The mean SSNR over all frames.\n",
    "    \"\"\"\n",
    "    ref = ref[0].numpy()\n",
    "    deg = deg[0].numpy()\n",
    "    ssnr_values = []\n",
    "    for start in range(0, len(ref) - frame_size, frame_size):\n",
    "        ref_frame = ref[start:start + frame_size]\n",
    "        # if np.all(ref_frame == 0):\n",
    "        #     continue  # Skip completely silent frames\n",
    "        deg_frame = deg[start:start + frame_size]\n",
    "        noise = ref_frame - deg_frame\n",
    "        signal_energy = np.sum(ref_frame ** 2) + eps\n",
    "        noise_energy = np.sum(noise ** 2) + eps\n",
    "        ssnr_values.append(10 * np.log10(signal_energy / noise_energy))\n",
    "    \n",
    "    # Filter out non-finite values which might occur if the noise is zero\n",
    "    ssnr_values = [x for x in ssnr_values if np.isfinite(x)]\n",
    "    \n",
    "    return np.mean(ssnr_values) if ssnr_values else 0 #float('nan') \n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assert_is_audio(*signal: torch.Tensor):\n",
    "    for s in signal:\n",
    "        assert len(s.shape) == 2\n",
    "        assert s.shape[0] == 1 or s.shape[0] == 2\n",
    "\n",
    "\n",
    "def is_silent(signal: torch.Tensor, silence_threshold: float = 1.5e-5) -> bool:\n",
    "    assert_is_audio(signal)\n",
    "    num_samples = signal.shape[-1]\n",
    "    return torch.linalg.norm(signal) / num_samples < silence_threshold\n",
    "\n",
    "\n",
    "def sdr(preds: torch.Tensor, target: torch.Tensor, eps: float = 1e-5) -> torch.Tensor:\n",
    "    s_target = torch.norm(target, dim=-1)**2 + eps\n",
    "    s_error = torch.norm(target - preds, dim=-1)**2 + eps\n",
    "    return 10 * torch.log10(s_target/s_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sisnr(preds: torch.Tensor, target: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    alpha = (torch.sum(preds * target, dim=-1, keepdim=True) + eps) / (torch.sum(target**2, dim=-1, keepdim=True) + eps)\n",
    "    target_scaled = alpha * target\n",
    "    noise = target_scaled - preds\n",
    "    s_target = torch.sum(target_scaled**2, dim=-1) + eps\n",
    "    s_error = torch.sum(noise**2, dim=-1) + eps\n",
    "    return 10 * torch.log10(s_target / s_error)\n",
    "\n",
    "\n",
    "def evaluate_separations(\n",
    "    separation_path: Union[str, Path],\n",
    "    dataset_path: Union[str, Path],\n",
    "    separation_sr: int,\n",
    "    filter_single_source: bool = True,\n",
    "    eps: float = 1e-8,\n",
    "    chunk_duration: float = 4.0, \n",
    "    overlap_duration: float = 2.0,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    separation_path = Path(separation_path)\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    df_entries = defaultdict(list)\n",
    "\n",
    "    files = os.listdir(dataset_path)\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "\n",
    "        try:\n",
    "            # load seperated tracks and resample track\n",
    "            separated_track, _ = torchaudio.load(separation_path / file) # load_chunks(separation_path/str(forder_id), [\"mixture\"])\n",
    "\n",
    "            # load original track\n",
    "            original_track, _ = torchaudio.load(dataset_path / file) #load_chunks(dataset_path/str(forder_id), [\"mixture\"])\n",
    "\n",
    "            # make mono\n",
    "            if separated_track.shape[0] > 1:\n",
    "                separated_track = separated_track[0].unsqueeze(0)\n",
    "            if original_track.shape[0] > 1:\n",
    "                original_track = original_track[0].unsqueeze(0)\n",
    "            \n",
    "            # Compare lengths and cut the longer one to the shorter one's length\n",
    "            min_length = min(separated_track.size(1), original_track.size(1))\n",
    "            separated_track = separated_track[:, :min_length]\n",
    "            original_track = original_track[:, :min_length]\n",
    "\n",
    "            # Further processing can be added here\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error processing {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        chunk_samples = int(chunk_duration * separation_sr)\n",
    "        overlap_samples = int(overlap_duration * separation_sr)\n",
    "\n",
    "        # Calculate the step size between consecutive sub-chunks\n",
    "        step_size = chunk_samples - overlap_samples\n",
    "\n",
    "        # Determine the number of evaluation chunks based on step_size\n",
    "        num_eval_chunks = math.ceil((original_track.shape[-1] - overlap_samples) / step_size)-1\n",
    "            \n",
    "        for i in range(num_eval_chunks):\n",
    "            start_sample = i * step_size\n",
    "            end_sample = start_sample + chunk_samples\n",
    "            \n",
    "            # Determine number of active signals in sub-chunk\n",
    "            num_active_signals = 0\n",
    "            for k in separated_track:\n",
    "                o = original_track[:,start_sample:end_sample]\n",
    "                if not is_silent(o):\n",
    "                    num_active_signals += 1\n",
    "            \n",
    "            # Skip sub-chunk if necessary\n",
    "            if filter_single_source and num_active_signals < 1:\n",
    "                continue\n",
    "\n",
    "            # Compute SI-SNRi for each stem\n",
    "            o = original_track[:,start_sample:end_sample]\n",
    "            s = separated_track[:,start_sample:end_sample]\n",
    "\n",
    "            # df_entries[k].append((sisnr(s, o, eps) ) - sisnr(m, o, eps))\n",
    "\n",
    "            # df_entries[k].append((sdr(s, o, eps) ).item()) \n",
    "            # print(file)\n",
    "            df_entries[\"snr\"].append((sisnr(s, o, eps) ).item()) #- sisnr(m, o, eps))\n",
    "\n",
    "            # Compute PESQ\n",
    "            pesq_score = 0.0 #compute_pesq(o, s, separation_sr)\n",
    "            df_entries[\"pesq\"].append(pesq_score)\n",
    "\n",
    "            # Compute SSNR\n",
    "            ssnr_score = 0.0 #compute_ssnr(o, s)\n",
    "            df_entries[\"ssnr\"].append(ssnr_score)\n",
    "\n",
    "\n",
    "            # Add chunk and sub-chunk info to dataframe entry\n",
    "            df_entries[\"start_sample\"].append(start_sample)\n",
    "            df_entries[\"end_sample\"].append(end_sample)\n",
    "            df_entries[\"file\"].append(file)\n",
    "\n",
    "\n",
    "\n",
    "    # Create and return dataframe\n",
    "    return pd.DataFrame(df_entries)\n",
    "\n",
    "base_dir = \"/home/karchkhadze/testing_sisdr/assets/fma/\"\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bvg_bwe\"\n",
    "dataset_path = base_dir + \"gt_bwe\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 44100, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bighifigan:{results[\"snr\"].mean()}')\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bvg_voc\"\n",
    "dataset_path = base_dir + \"gt_voc\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 22050, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bigvgan:{results[\"snr\"].mean()}')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "separation_dir = base_dir + \"bvg_m2s\"\n",
    "dataset_path = base_dir + \"gt_stereo\"\n",
    "\n",
    "# Compute metrics\n",
    "results = evaluate_separations(separation_dir, dataset_path, 44100, eps=1e-8 )\n",
    "\n",
    "print(f'\\nResults bigvgan-base:{results[\"snr\"].mean()}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "# #############################################################\n",
    "\n",
    "# separation_dir = \"/home/karchkhadze/testing_sisdr/assets/generated/bvg_bwe\"\n",
    "# dataset_path = base_dir + \"gt_bwe\"\n",
    "\n",
    "# # Compute metrics\n",
    "# results = evaluate_separations(separation_dir, dataset_path, 44100, eps=1e-8 )\n",
    "\n",
    "# print(f'\\nResults bighifigan:{results[\"snr\"].mean()}')\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "# separation_dir = \"/home/karchkhadze/testing_sisdr/assets/generated/bvg_voc\"\n",
    "# dataset_path = base_dir + \"g_voct\"\n",
    "\n",
    "# # Compute metrics\n",
    "# results = evaluate_separations(separation_dir, dataset_path, 22050, eps=1e-8 )\n",
    "\n",
    "# print(f'\\nResults bigvgan:{results[\"snr\"].mean()}')\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "# separation_dir = \"/home/karchkhadze/testing_sisdr/assets/generated/bvg_m2s\"\n",
    "# dataset_path = base_dir + \"gt_stereo\"\n",
    "\n",
    "# # Compute metrics\n",
    "# results = evaluate_separations(separation_dir, dataset_path, 44100, eps=1e-8 )\n",
    "\n",
    "# print(f'\\nResults bigvgan-base:{results[\"snr\"].mean()}')\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "# separation_dir = base_dir + \"sc-wavernn\"\n",
    "# dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# # Compute metrics\n",
    "# results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "# print(f'\\nResults sc-wavernn:{results[\"snr\"].mean()}')\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "# separation_dir = base_dir + \"univnet\"\n",
    "# dataset_path = base_dir + \"gt\"\n",
    "\n",
    "# # Compute metrics\n",
    "# results = evaluate_separations(separation_dir, dataset_path, 24000, eps=1e-8 )\n",
    "\n",
    "# print(f'\\nResults univnet:{results[\"snr\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicldm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
